{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2202d75",
   "metadata": {},
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff51410",
   "metadata": {},
   "source": [
    "Write a function cut_suffix which takes a string and a suffix. A function should return this string without the given suffix.\n",
    "\n",
    "cut_suffix(\"foobar\", \"bar\")\n",
    ">>> \"foo\"\n",
    "\n",
    "cut_suffix(\"foobar\", \"boo\")\n",
    ">>> \"foobar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_suffix(sentence: str, suffix: str) -> str:\n",
    "    return sentence.removesuffix(suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a909db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_suffix(\"foobar\", \"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e278ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foobar'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_suffix(\"foobar\", \"boo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674f56db",
   "metadata": {},
   "source": [
    "Write a function boxed which takes a string and two arguments: a symbol fill and a number pad. A result of the boxed function execution should be a string surrounded by fill symbols as it’s shown in the example.\n",
    "\n",
    "print(boxed(\"Hello world\", fill=\"*\", pad=2))\n",
    "print(boxed(\"Fishy\", fill=\"#\", pad=1))\n",
    "result:\n",
    "\n",
    "*****************\n",
    "** Hello world **\n",
    "*****************\n",
    "\n",
    "#########\n",
    "# Fishy #\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9814e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "** Hello world **\n",
      "*****************\n",
      "#########\n",
      "# Fishy #\n",
      "#########\n"
     ]
    }
   ],
   "source": [
    "def boxed(sentence: str, fill: str = '#', pad: int = 1):\n",
    "    return (fill*(pad*2 + 2 + len(sentence))) + '\\n' \\\n",
    "        + ((fill*pad) + ' ' + sentence + ' ' + (fill*pad)) + '\\n' \\\n",
    "        + (fill*(pad*2 + 2 + len(sentence)))\n",
    "\n",
    "\n",
    "print(boxed(\"Hello world\", fill=\"*\", pad=2))\n",
    "print(boxed(\"Fishy\", fill=\"#\", pad=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0970bbb",
   "metadata": {},
   "source": [
    "She-bang – a sequence #! which is used in Unix-like systems to run executable scripts. She-bang is always written on the first line in the script. After she-bang there is path to an interpreter program written, for example:\n",
    "\n",
    "#! /bin/sh\n",
    "\n",
    "#!/usr/bin/env python -v\n",
    "\n",
    "Look at more example of she-bang here: http://en.wikipedia.org/wiki/Shebang_(Unix)\n",
    "\n",
    "Write a function parse_shebang which takes a path to an executable script and return a path to an interpreter program, if a script contains she-bang and None otherwise. For the scripts in the example above:\n",
    "\n",
    "parse_shebang(\"./example1.txt\")\n",
    ">>> \"/bin/sh\"\n",
    "\n",
    "parse_shebang(\"./example2.txt\")\n",
    ">>> \"/usr/bin/env python -v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1492b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_shebang(path: str):\n",
    "    with open(path, mode='r') as file:\n",
    "        first_line = file.readline()\n",
    "        if first_line.startswith('#!'):\n",
    "            index = 2\n",
    "            while True:\n",
    "                if first_line[index] == '/':\n",
    "                    break\n",
    "                index += 1\n",
    "            return first_line[index:]\n",
    "    \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e00c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bin/sh'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_shebang(\"./example_1.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee1be54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/env python -v\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_shebang(\"./example_2.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42d24a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e06aa88",
   "metadata": {},
   "source": [
    "# Special Task (Bonus 4%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5097440",
   "metadata": {},
   "source": [
    "A probabilistic langauge model describes pieces of text of some language in terms of random processes. One of the simplest language model can be stated the following way. Let’s assume that we know a set of all words in a language. Let’s generate words in a sentence from left to right one-by-one:\n",
    "\n",
    "Randomly take first two words from the set of all words.\n",
    "Each i’th word we will generate having from two previous (i - 1)’th and (i - 2)’th words.\n",
    "Let’s try to build a language model based on lyrics of Taylor Swift's songs!\n",
    "\n",
    "1.Write a function words which takes a text file and returns a list of words from a file:\n",
    "\n",
    "import io\n",
    "handle = io.StringIO(\"\"\"Can we always be this close forever and ever?\n",
    "And ah, take me out, and take me home forever and ever.\"\"\")\n",
    "words(handle)\n",
    ">>>['Can', 'we', 'always', 'be', 'this', 'close', 'forever', 'and', 'ever?\\n', 'And', 'ah,', 'take', 'me', 'out,', 'and', 'take', 'me', 'home', 'forever', 'and', 'ever.',\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae33a38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74afa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can', 'we', 'always', 'be', 'this', 'close', 'forever', 'and', 'ever?\\n', 'And', 'ah,', 'take', 'me', 'out,', 'and', 'take', 'me', 'home', 'forever', 'and', 'ever.']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "handle = io.StringIO(\"\"\"Can we always be this close forever and ever?\n",
    "And ah, take me out, and take me home forever and ever.\"\"\")\n",
    "\n",
    "def words(handle: io.StringIO) -> list[str]:\n",
    "    text = list()\n",
    "    while True:\n",
    "        line = handle.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        text.extend(line.split(' '))\n",
    "    return text\n",
    "\n",
    "print(words(handle))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356faf96",
   "metadata": {},
   "source": [
    "2.Write a function transition_matrix which takes a list of words and returns a dictionary. This dictionary for every pair of words (u, v) contains a list of words w which follow words u and v in the input list of words. For the example above:\n",
    "language = words(handle)\n",
    "m = transition_matrix(language)\n",
    "m[(\"take\", \"me\")]\n",
    ">>> [\"out,\", \"home\"]\n",
    "\n",
    "m[(\"we\", \"always\")]\n",
    ">>> [\"be\"]\n",
    "\n",
    "m[(\"forever\", \"and\")]\n",
    ">>> [\"ever?\\n\", \"ever.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "566c46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(word_list: list[str]) -> dict:\n",
    "    result = dict()\n",
    "    for index in range(len(word_list)-2):\n",
    "        word_pair = (word_list[index], word_list[index + 1])\n",
    "        if word_pair in result.keys():\n",
    "            result[word_pair].append(word_list[index + 2])\n",
    "        else:\n",
    "            result[word_pair] = [word_list[index + 2]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a47c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "handle = io.StringIO(\"\"\"Can we always be this close forever and ever?\n",
    "And ah, take me out, and take me home forever and ever.\"\"\")\n",
    "\n",
    "language = words(handle)\n",
    "m = transition_matrix(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1541b633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['out,', 'home']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[(\"take\", \"me\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4763bdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[(\"we\", \"always\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b67d811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ever?\\n', 'ever.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[(\"forever\", \"and\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4960b",
   "metadata": {},
   "source": [
    "3.Write a function markov_chain which generates sentences of a defined size. A function takes three parameters:\n",
    "a list of words, a result words function execution,\n",
    "a dictionary, built with transition_matrix function,\n",
    "an integer – a number of words in sentence to be generated.\n",
    "Let me remind how to generate random sentences. Let’s generate words in a sentence from left to right one-by-one:\n",
    "\n",
    "Randomly take two first words from all words list words.\n",
    "Each i’th word will be generated using previous two (i - 1)’th and (i - 2)’th words (with help of transition_matrix).\n",
    "If this pair didn’t happen to exist (it’s in transition_matrix dictionary) then i’th word is taken randomly from the set of all words.\n",
    "You will need functions random.randint and random.choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f6b2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def markov_chain(words: list[str], transition_matrix: dict[tuple[str, str]: list[str]], number: int) -> str:\n",
    "    result = list()\n",
    "    result.append(random.choice(words))\n",
    "    result.append(random.choice(words))\n",
    "    for index in range(2, number):\n",
    "        if (result[index - 1], result[index - 2]) in transition_matrix.keys():\n",
    "            result.append(random.choice(transition_matrix[(result[index - 1], result[index - 2])]))\n",
    "        else:\n",
    "            result.append(random.choice(words))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298802c0",
   "metadata": {},
   "source": [
    "Write a function taylor_swifter() which takes a path to a file taylor_swift.txt and an integer – a length of a sentence and returns a sentence of specified language on Taylor Swift's language.\n",
    "print(taylor_swifter(\"./taylor_swift.txt\", 30))\n",
    "\n",
    ">>>'well dancing pack I got this music in my head tell me to the garden? In the garden, would you trust me If I told you it was never mine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddb7ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_swifter(path: str, sentence_length: int) -> str:\n",
    "    handle = open(path, 'r')\n",
    "    word_list = words(handle)\n",
    "    handle.close()\n",
    "\n",
    "    tf = transition_matrix(word_list)\n",
    "\n",
    "    return markov_chain(word_list, tf, sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07ad4953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you all for wonderstruck, go?\n",
      " me made\"\n",
      " just thinkin' by out doesn't \"I fogs call got every a case feeling I the Got \" could book are again\n",
      " word And all town\n",
      " the I, style\n",
      " warn same and Always \"Yes\"\n",
      " It's May where party\n",
      " his true\n",
      " Please down you come summer\n",
      " these I hair, was see One me Oh, time\n",
      " here shit\n",
      " my I with celebrated\n",
      " Your you back I\n",
      " the you tell I'm me insincerity, me I'm queens\n",
      " all)\n",
      " 'Cause Running my away So I the told I you just never remembered\n",
      " so Your read still weekend\n",
      " And a\n"
     ]
    }
   ],
   "source": [
    "print(taylor_swifter('./Taylor_Swift.txt', 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9232e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
